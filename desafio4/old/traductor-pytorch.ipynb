{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfa39F4lsLf3"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## LSTM Traductor\n",
    "Ejemplo basado en [LINK](https://stackabuse.com/python-for-nlp-neural-machine-translation-with-seq2seq-in-keras/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqO0PRcFsPTe"
   },
   "source": [
    "### Datos\n",
    "El objecto es utilizar datos disponibles de Anki de traducciones de texto en diferentes idiomas. Se construirá un modelo traductor seq2seq utilizando encoder-decoder.\\\n",
    "[LINK](https://www.manythings.org/anki/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cq3YXak9sGHd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métrica de accuracy con máscara de padding\n",
    "def sequence_acc(logits, tgt_idx, pad_idx=0):\n",
    "    \"\"\"\n",
    "    logits : [B, L, V]  salida del modelo\n",
    "    tgt_idx: [B, L]     índices ground-truth\n",
    "    \"\"\"\n",
    "    pred_idx = logits.argmax(dim=-1)\n",
    "    mask     = tgt_idx.ne(pad_idx)            # True donde hay palabra\n",
    "    correct  = (pred_idx.eq(tgt_idx) & mask).float()\n",
    "    total = mask.sum()\n",
    "    return correct.sum() / total if total > 0 else torch.tensor(0.0)\n",
    "\n",
    "# Función de entrenamiento\n",
    "def train(model,\n",
    "          train_loader,\n",
    "          valid_loader,\n",
    "          optimizer,\n",
    "          criterion,              \n",
    "          epochs     = 50,\n",
    "          patience   = 7,\n",
    "          min_delta  = 1e-4,\n",
    "          device     = \"cuda\",\n",
    "          pad_idx    = 0):\n",
    "    model.to(device)\n",
    "    best_val_loss = float(\"inf\")\n",
    "    wait          = 0\n",
    "    best_state    = None\n",
    "    history = {\"loss\": [], \"accuracy\": [], \"val_loss\": [], \"val_accuracy\": []}\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # ----- TRAIN -----\n",
    "        model.train()\n",
    "        tot_loss, tot_acc = 0, 0\n",
    "        for enc_in, dec_in, tgt_idx in train_loader:\n",
    "            enc_in   = enc_in.to(device)\n",
    "            dec_in   = dec_in.to(device)\n",
    "            tgt_idx  = tgt_idx.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(enc_in, dec_in)            # [B, L, V]\n",
    "            B, L, V = logits.shape\n",
    "            loss = criterion(logits.view(-1, V), tgt_idx.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tot_loss += loss.item()\n",
    "            tot_acc  += sequence_acc(logits, tgt_idx, pad_idx).item()\n",
    "        train_loss = tot_loss / len(train_loader)\n",
    "        train_acc  = tot_acc  / len(train_loader)\n",
    "\n",
    "        # ----- VALID -----\n",
    "        model.eval()\n",
    "        val_loss, val_acc = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for enc_in, dec_in, tgt_idx in valid_loader:\n",
    "                enc_in  = enc_in.to(device)\n",
    "                dec_in  = dec_in.to(device)\n",
    "                tgt_idx = tgt_idx.to(device)\n",
    "                logits = model(enc_in, dec_in)\n",
    "                B, L, V = logits.shape\n",
    "                loss = criterion(logits.view(-1, V), tgt_idx.view(-1))\n",
    "                val_loss += loss.item()\n",
    "                val_acc  += sequence_acc(logits, tgt_idx, pad_idx).item()\n",
    "        val_loss /= len(valid_loader)\n",
    "        val_acc  /= len(valid_loader)\n",
    "        history[\"loss\"].append(train_loss)\n",
    "        history[\"accuracy\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_accuracy\"].append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch:3d}: \"\n",
    "              f\"Train L={train_loss:.4f} A={train_acc:.4f} | \"\n",
    "              f\"Val L={val_loss:.4f} A={val_acc:.4f}\")\n",
    "\n",
    "        # ----- EARLY STOPPING -----\n",
    "        if val_loss + min_delta < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_state    = model.state_dict()\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BFiCH8nxoIY"
   },
   "source": [
    "### 1 - Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1655153154355,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "-9aNLZBDtA5J",
    "outputId": "68de3ded-aa96-40fe-fab5-8083525e8c67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de rows disponibles: 118964\n",
      "Cantidad de rows utilizadas: 118964\n"
     ]
    }
   ],
   "source": [
    "# dataset_file\n",
    "text_file = \"./clase/spa-eng/spa.txt\"\n",
    "with open(text_file, encoding=\"utf8\") as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "# Por limitaciones de RAM no se leen todas las filas\n",
    "MAX_NUM_SENTENCES = 0\n",
    "\n",
    "# Mezclar el dataset, forzar semilla siempre igual\n",
    "np.random.seed([40])\n",
    "np.random.shuffle(lines)\n",
    "\n",
    "input_sentences = []\n",
    "output_sentences = []\n",
    "output_sentences_inputs = []\n",
    "count = 0\n",
    "\n",
    "if MAX_NUM_SENTENCES == 0:\n",
    "    MAX_NUM_SENTENCES = len(lines)\n",
    "for line in lines:\n",
    "    count += 1\n",
    "    if count > MAX_NUM_SENTENCES:\n",
    "        break\n",
    "\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "\n",
    "    # Input sentence --> eng\n",
    "    # output --> spa\n",
    "    input_sentence, output = line.rstrip().split('\\t')\n",
    "\n",
    "    # output sentence (decoder_output) tiene <eos>\n",
    "    output_sentence = output + ' <eos>'\n",
    "    # output sentence input (decoder_input) tiene <sos>\n",
    "    output_sentence_input = '<sos> ' + output\n",
    "\n",
    "    input_sentences.append(input_sentence)\n",
    "    output_sentences.append(output_sentence)\n",
    "    output_sentences_inputs.append(output_sentence_input)\n",
    "\n",
    "print(\"Cantidad de rows disponibles:\", len(lines))\n",
    "print(\"Cantidad de rows utilizadas:\", len(input_sentences))\n",
    "print(input_sentences[0], output_sentences[0], output_sentences_inputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8P-ynUNP5xp6"
   },
   "source": [
    "### 2 - Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5WAZGOTfGyha"
   },
   "outputs": [],
   "source": [
    "# Definir el tamaño máximo del vocabulario\n",
    "MAX_VOCAB_SIZE = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1655153154356,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "eF1W6peoFGXA",
    "outputId": "e748ad10-0c8d-4bca-ab4c-76f1974e12cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el vocabulario: 13524\n",
      "Sentencia de entrada más larga: 47\n"
     ]
    }
   ],
   "source": [
    "# Tokenizar las palabras con el Tokenizer de Keras\n",
    "# Definir una máxima cantidad de palabras a utilizar:\n",
    "# - num_words --> the maximum number of words to keep, based on word frequency.\n",
    "# - Only the most common num_words-1 words will be kept.\n",
    "from clase.torch_helpers import Tokenizer\n",
    "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "input_tokenizer.fit_on_texts(input_sentences)\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
    "\n",
    "word2idx_inputs = input_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n",
    "\n",
    "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
    "print(\"Sentencia de entrada más larga:\", max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 584,
     "status": "ok",
     "timestamp": 1655153154936,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "zBzdKiTVIBYY",
    "outputId": "f313cf87-642e-4671-b88d-90ecd0e80c28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el vocabulario: 26341\n",
      "Sentencia de salida más larga: 50\n"
     ]
    }
   ],
   "source": [
    "# A los filtros de símbolos del Tokenizer agregamos el \"¿\",\n",
    "# sacamos los \"<>\" para que no afectar nuestros tokens\n",
    "output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n')\n",
    "output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)\n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
    "\n",
    "word2idx_outputs = output_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n",
    "\n",
    "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE) # Se suma 1 por el primer <sos>\n",
    "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
    "print(\"Sentencia de salida más larga:\", max_out_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xqb8ZJ4sJHgv"
   },
   "source": [
    "Como era de esperarse, las sentencias en castellano son más largas que en inglés, y lo mismo sucede con su vocabulario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGOn9N57IuYz"
   },
   "source": [
    "A la hora de realiza padding es importante teneer en cuenta que en el encoder los ceros se agregan al comienoz y en el decoder al final. Esto es porque la salida del encoder está basado en las últimas palabras de la sentencia (son las más importantes), mientras que en el decoder está basado en el comienzo de la secuencia de salida ya que es la realimentación del sistema y termina con fin de sentencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1655153154937,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "q0Ob4hAWJkcv",
    "outputId": "9152d151-b863-49c9-e527-940d37a85385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de rows del dataset: 118964\n",
      "encoder_input_sequences shape: (118964, 47)\n",
      "decoder_input_sequences shape: (118964, 50)\n"
     ]
    }
   ],
   "source": [
    "from clase.torch_helpers import pad_sequences\n",
    "print(\"Cantidad de rows del dataset:\", len(input_integer_seq))\n",
    "\n",
    "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n",
    "\n",
    "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
    "print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)\n",
    "\n",
    "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
    "print(\"decoder_output_sequences shape:\", decoder_output_sequences.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos un dataset sin one_hot encoding para ocupar menos memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_size: 47\n",
      "decoder_input_size: 50\n",
      "Output dim 50\n"
     ]
    }
   ],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Devuelve tensores int64 con PAD=0.\n",
    "    ─ encoder_inputs : [N, T_enc]\n",
    "    ─ decoder_inputs : [N, T_dec]   (<sos> + frase)\n",
    "    ─ decoder_outputs: [N, T_dec]   (frase + <eos>)\n",
    "    \"\"\"\n",
    "    def __init__(self, enc_arr: np.ndarray,\n",
    "                       dec_in_arr: np.ndarray,\n",
    "                       dec_out_arr: np.ndarray):\n",
    "\n",
    "        # Convertir a tensores int64\n",
    "        self.encoder_inputs  = torch.from_numpy(enc_arr    .astype(np.int64))\n",
    "        self.decoder_inputs  = torch.from_numpy(dec_in_arr .astype(np.int64))\n",
    "        self.decoder_outputs = torch.from_numpy(dec_out_arr.astype(np.int64))\n",
    "\n",
    "        assert len(self.encoder_inputs) == len(self.decoder_inputs) == len(self.decoder_outputs), \\\n",
    "            \"Los tres arrays deben tener la misma longitud\"\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.encoder_inputs [idx],\n",
    "                self.decoder_inputs [idx],\n",
    "                self.decoder_outputs[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoder_inputs)\n",
    "    \n",
    "# Construcción\n",
    "data_set = Seq2SeqDataset(encoder_input_sequences,\n",
    "                          decoder_input_sequences,\n",
    "                          decoder_output_sequences)\n",
    "\n",
    "encoder_input_size = data_set.encoder_inputs.shape[1]\n",
    "print(\"encoder_input_size:\", encoder_input_size)\n",
    "\n",
    "decoder_input_size = data_set.decoder_inputs.shape[1]\n",
    "print(\"decoder_input_size:\", decoder_input_size)\n",
    "\n",
    "output_dim = data_set.decoder_outputs.shape[1]\n",
    "print(\"Output dim\", output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1655153159536,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "sUDPZeuAU1RI",
    "outputId": "f19e0632-7cfd-4671-dddc-edbcf715788f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 95172\n",
      "Tamaño del conjunto de validacion: 23792\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "valid_set_size = int(len(data_set) * 0.2)\n",
    "train_set_size = len(data_set) - valid_set_size\n",
    "\n",
    "train_set = torch.utils.data.Subset(data_set, range(train_set_size))\n",
    "valid_set = torch.utils.data.Subset(data_set, range(train_set_size, len(data_set)))\n",
    "\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", len(train_set))\n",
    "print(\"Tamaño del conjunto de validacion:\", len(valid_set))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True, num_workers=0, pin_memory=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=128, shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CJIsLBbj6rg"
   },
   "source": [
    "### 3 - Preparar los embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizan dos embeddings pre entrenados de Fastext para el ingles y el español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Mosj2-x-kXBK"
   },
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "model_embeddings = load_facebook_vectors(\"clase/cc.en.300.bin\")  \n",
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "model_embeddings_es = load_facebook_vectors(\"clase/cc.es.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13525, 300)\n",
      "(26342, 300)\n"
     ]
    }
   ],
   "source": [
    "vocab_size_in  = max(word2idx_inputs .values()) + 1   \n",
    "vocab_size_out = max(word2idx_outputs.values()) + 1   \n",
    "embed_dim = 300\n",
    "# Inglés\n",
    "embedding_matrix = np.zeros((vocab_size_in, embed_dim), dtype=np.float32)\n",
    "for w, idx in word2idx_inputs.items():\n",
    "    # idx incluye todos los valores hasta max_index\n",
    "    if w in model_embeddings:\n",
    "        embedding_matrix[idx] = model_embeddings[w]\n",
    "# Español\n",
    "embedding_matrix_es = np.zeros((vocab_size_out, embed_dim), dtype=np.float32)\n",
    "for w, idx in word2idx_outputs.items():\n",
    "    if w in model_embeddings_es:\n",
    "        embedding_matrix_es[idx] = model_embeddings_es[w]\n",
    "print(embedding_matrix.shape)\n",
    "print(embedding_matrix_es.shape)\n",
    "nb_words = embedding_matrix.shape[0]\n",
    "num_words_output = embedding_matrix_es.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vKbhjtIwPgM"
   },
   "source": [
    "### 4 - Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14732,
     "status": "ok",
     "timestamp": 1655153181107,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "3fm3HCLMPSG-",
    "outputId": "39be3183-0a69-49a5-8aa1-9f24026edf32"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.lstm_size = 256\n",
    "        self.num_layers = 2\n",
    "        self.embedding_dim = embed_dim\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=self.embedding_dim, padding_idx=0)\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "        self.embedding.weight.requires_grad = False  # marcar como layer no entrenable (freeze)\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.lstm_size, batch_first=True,\n",
    "                            num_layers=self.num_layers, dropout=0.2) # LSTM layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.embedding(x)\n",
    "        lstm_output, (ht, ct) = self.lstm(out)\n",
    "        return (ht, ct)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, output_dim):\n",
    "        super().__init__()\n",
    "        self.lstm_size = 256\n",
    "        self.num_layers = 2\n",
    "        self.embedding_dim = embed_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim, padding_idx=0)\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix_es))\n",
    "        self.embedding.weight.requires_grad = True  # Opcional: Freezar\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.lstm_size, batch_first=True,\n",
    "                            num_layers=self.num_layers, dropout=0.2) # LSTM layer\n",
    "        self.fc1 = nn.Linear(in_features=self.lstm_size, out_features=self.output_dim) # Fully connected layer\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        out = self.embedding(x)\n",
    "        lstm_output, (ht, ct) = self.lstm(out, prev_state)\n",
    "        out = self.fc1(lstm_output)  # conserva la dimensión de secuencia\n",
    "        return out, (ht, ct)\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, encoder_input, decoder_input):\n",
    "        batch_size = decoder_input.shape[0]\n",
    "        decoder_input_len = decoder_input.shape[1]\n",
    "        vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(batch_size, decoder_input_len, vocab_size, device=encoder_input.device)\n",
    "        # ultimo hidden state del encoder, primer estado oculto del decoder\n",
    "        prev_state = self.encoder(encoder_input)\n",
    "        # En la primera iteracion se toma el primer token de target (<sos>)\n",
    "        input = decoder_input[:, 0:1]\n",
    "        for t in range(decoder_input_len):\n",
    "            input = decoder_input[:, t:t+1]\n",
    "            output, prev_state = self.decoder(input, prev_state)\n",
    "            # top1 = output.argmax(1).view(-1, 1)\n",
    "            top1 = output[:, -1, :].argmax(1).view(-1, 1)\n",
    "            # guardar cada salida (softmax)\n",
    "            outputs[:, t, :] = output.squeeze(1)\n",
    "            # outputs[:, t, :] = output\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Seq2Seq                                  [1, 50, 26342]            --\n",
       "├─Encoder: 1-1                           [2, 1, 128]               --\n",
       "│    └─Embedding: 2-1                    [1, 47, 300]              (4,057,500)\n",
       "│    └─LSTM: 2-2                         [1, 47, 128]              352,256\n",
       "├─Decoder: 1-2                           [1, 1, 26342]             --\n",
       "│    └─Embedding: 2-3                    [1, 1, 300]               7,902,600\n",
       "│    └─LSTM: 2-4                         [1, 1, 128]               352,256\n",
       "│    └─Linear: 2-5                       [1, 1, 26342]             3,398,118\n",
       "├─Decoder: 1-3                           [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-6                    [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-7                         [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-8                       [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-4                           [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-9                    [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-10                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-11                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-5                           [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-12                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-13                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-14                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-6                           [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-15                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-16                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-17                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-7                           [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-18                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-19                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-20                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-8                           [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-21                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-22                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-23                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-9                           [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-24                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-25                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-26                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-10                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-27                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-28                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-29                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-11                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-30                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-31                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-32                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-12                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-33                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-34                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-35                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-13                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-36                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-37                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-38                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-14                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-39                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-40                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-41                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-15                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-42                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-43                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-44                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-16                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-45                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-46                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-47                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-17                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-48                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-49                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-50                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-18                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-51                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-52                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-53                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-19                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-54                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-55                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-56                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-20                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-57                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-58                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-59                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-21                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-60                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-61                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-62                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-22                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-63                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-64                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-65                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-23                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-66                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-67                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-68                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-24                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-69                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-70                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-71                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-25                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-72                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-73                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-74                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-26                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-75                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-76                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-77                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-27                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-78                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-79                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-80                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-28                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-81                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-82                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-83                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-29                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-84                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-85                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-86                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-30                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-87                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-88                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-89                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-31                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-90                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-91                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-92                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-32                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-93                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-94                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-95                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-33                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-96                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-97                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-98                      [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-34                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-99                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-100                       [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-101                     [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-35                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-102                  [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-103                       [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-104                     [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-36                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-105                  [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-106                       [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-107                     [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-37                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-108                  [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-109                       [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-110                     [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-38                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-111                  [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-112                       [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-113                     [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-39                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-114                  [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-115                       [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-116                     [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-40                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-117                  [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-118                       [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-119                     [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-41                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-120                  [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-121                       [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-122                     [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-42                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-123                  [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-124                       [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-125                     [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-43                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-126                  [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-127                       [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-128                     [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-44                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-129                  [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-130                       [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-131                     [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-45                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-132                  [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-133                       [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-134                     [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-46                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-135                  [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-136                       [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-137                     [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-47                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-138                  [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-139                       [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-140                     [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-48                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-141                  [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-142                       [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-143                     [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-49                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-144                  [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-145                       [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-146                     [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-50                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-147                  [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-148                       [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-149                     [1, 1, 26342]             (recursive)\n",
       "├─Decoder: 1-51                          [1, 1, 26342]             (recursive)\n",
       "│    └─Embedding: 2-150                  [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-151                       [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-152                     [1, 1, 26342]             (recursive)\n",
       "==========================================================================================\n",
       "Total params: 16,062,730\n",
       "Trainable params: 12,005,230\n",
       "Non-trainable params: 4,057,500\n",
       "Total mult-adds (Units.MEGABYTES): 603.26\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 10.87\n",
       "Params size (MB): 64.25\n",
       "Estimated Total Size (MB): 75.12\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(vocab_size=nb_words)\n",
    "if cuda: encoder.cuda()\n",
    "decoder = Decoder(vocab_size=num_words_output, output_dim=num_words_output)\n",
    "if cuda: decoder.cuda()\n",
    "seq2seq = Seq2Seq(encoder, decoder).to(device)\n",
    "if cuda: seq2seq.cuda()\n",
    "\n",
    "# Diferentes learning rates para hacer fine tuning al embedding en español de Fasttext\n",
    "emb_params   = list(decoder.embedding.parameters())            # solo embedding ES\n",
    "other_params = [p for n, p in seq2seq.named_parameters()\n",
    "                if \"decoder.embedding\" not in n]               # resto de la red\n",
    "lr = 0.01\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [\n",
    "        {\"params\": emb_params,   \"lr\": lr*0.01},   # LR pequeño para embedding\n",
    "        {\"params\": other_params, \"lr\": lr},   # LR normal resto\n",
    "    ],\n",
    "    betas=(0.9, 0.98),\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)  # Omito el padding para que no falsee la metrica\n",
    "\n",
    "x_enc = data_set[0:1][0]\n",
    "x_dec = data_set[0:1][1]\n",
    "summary(seq2seq,\n",
    "        input_data=(x_enc.to(device).long(), x_dec.to(device).long()),\n",
    "        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 597334,
     "status": "ok",
     "timestamp": 1655153778405,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "VDB0KWIegt8s",
    "outputId": "d1e002a8-fa8e-4dfc-f144-a95732026f94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1: Train L=6.2033 A=0.1779 | Val L=5.7144 A=0.1995\n",
      "Epoch   2: Train L=5.2496 A=0.2163 | Val L=4.9122 A=0.2481\n",
      "Epoch   3: Train L=4.3242 A=0.2918 | Val L=4.1632 A=0.3234\n",
      "Epoch   4: Train L=3.7008 A=0.3478 | Val L=3.8181 A=0.3664\n",
      "Epoch   5: Train L=3.2961 A=0.3854 | Val L=3.6525 A=0.3906\n",
      "Epoch   6: Train L=3.0076 A=0.4145 | Val L=3.5323 A=0.4099\n",
      "Epoch   7: Train L=2.7864 A=0.4384 | Val L=3.4545 A=0.4264\n",
      "Epoch   8: Train L=2.6082 A=0.4587 | Val L=3.4089 A=0.4375\n",
      "Epoch   9: Train L=2.4689 A=0.4758 | Val L=3.3868 A=0.4475\n",
      "Epoch  10: Train L=2.3569 A=0.4898 | Val L=3.3991 A=0.4493\n",
      "Epoch  11: Train L=2.2644 A=0.5029 | Val L=3.3795 A=0.4573\n",
      "Epoch  12: Train L=2.1928 A=0.5130 | Val L=3.3780 A=0.4583\n",
      "Epoch  13: Train L=2.1235 A=0.5238 | Val L=3.4021 A=0.4613\n",
      "Epoch  14: Train L=2.0659 A=0.5327 | Val L=3.3886 A=0.4676\n",
      "Epoch  15: Train L=2.0163 A=0.5407 | Val L=3.4090 A=0.4669\n",
      "Epoch  16: Train L=1.9841 A=0.5465 | Val L=3.4239 A=0.4728\n",
      "Epoch  17: Train L=1.9444 A=0.5530 | Val L=3.4333 A=0.4728\n",
      "Epoch  18: Train L=1.9036 A=0.5602 | Val L=3.4371 A=0.4722\n",
      "Epoch  19: Train L=1.8708 A=0.5655 | Val L=3.4722 A=0.4737\n",
      "Epoch  20: Train L=1.8454 A=0.5699 | Val L=3.4428 A=0.4787\n",
      "Epoch  21: Train L=1.8146 A=0.5749 | Val L=3.4860 A=0.4783\n",
      "Epoch  22: Train L=1.7909 A=0.5798 | Val L=3.4760 A=0.4787\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "history, model = train(seq2seq,\n",
    "                train_loader,\n",
    "                valid_loader,\n",
    "                optimizer,\n",
    "                criterion,\n",
    "                epochs=100,\n",
    "                device=device,\n",
    "                patience=8\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1655154657801,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "pZzm3tx059Zv",
    "outputId": "b7a08ad6-392e-4e40-8491-fb707d23254c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_count = range(1, len(history['accuracy']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=history['accuracy'], label='train')\n",
    "sns.lineplot(x=epoch_count,  y=history['val_accuracy'], label='valid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zbwn0ekDy_s2"
   },
   "source": [
    "### 5 - Inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "71XeCtfYmOFx"
   },
   "outputs": [],
   "source": [
    "# Armar lo conversores de indice a palabra:\n",
    "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(input_text, \n",
    "                       model, \n",
    "                       input_tokenizer, \n",
    "                       word2idx_outputs, \n",
    "                       idx2word_target,\n",
    "                       max_input_len,\n",
    "                       max_output_len,\n",
    "                       device):\n",
    "    model.eval()\n",
    "    # 1) Tokenizar y paddear\n",
    "    seq = input_tokenizer.texts_to_sequences([input_text.lower()])[0]\n",
    "    seq = pad_sequences([seq], maxlen=max_input_len, padding='post')\n",
    "    encoder_input = torch.tensor(seq, dtype=torch.long).to(device)      # [1, max_input_len]\n",
    "    # 2) Pasar por el encoder\n",
    "    prev_state = model.encoder(encoder_input)                           # (h, c)\n",
    "    # 3) Iniciar decoder con <sos>\n",
    "    sos = word2idx_outputs['<sos>']\n",
    "    eos = word2idx_outputs['<eos>']\n",
    "    decoder_input = torch.tensor([[sos]], dtype=torch.long).to(device)  # [1, 1]\n",
    "    output_words = []\n",
    "    # 4) Loop hasta max_output_len o hasta <eos>\n",
    "    for _ in range(max_output_len):\n",
    "        logits, prev_state = model.decoder(decoder_input, prev_state)\n",
    "        # logits: [1, 1, vocab_size]\n",
    "        logits = logits.squeeze(1)           # [1, vocab_size]\n",
    "        topi = logits.argmax(dim=1)          # [1]\n",
    "        idx = topi.item()                    # entero\n",
    "        if idx == eos:\n",
    "            break\n",
    "        output_words.append(idx2word_target[idx])\n",
    "        # re-alimentar al decoder\n",
    "        decoder_input = topi.unsqueeze(1)    # [1, 1]\n",
    "    return ' '.join(output_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:    My mother say hi.\n",
      "Output:   él decidió hilo dental a la velocidad de tom y olviden que visitara boston\n"
     ]
    }
   ],
   "source": [
    "input_test = \"My mother say hi.\"\n",
    "translation = translate_sentence(\n",
    "    input_text=input_test,\n",
    "    model=model,\n",
    "    input_tokenizer=input_tokenizer,\n",
    "    word2idx_outputs=word2idx_outputs,\n",
    "    idx2word_target=idx2word_target,\n",
    "    max_input_len=max_input_len,\n",
    "    max_output_len=max_out_len,  \n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"Input:   \", input_test)\n",
    "print(\"Output:  \", translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:    This movie is politically incorrect.\n",
      "Output:   espero que tom gane el concierto antes de que se le ocurra matar a un canadiense\n"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(len(input_sentences))\n",
    "input_test = input_sentences[i:i+1][0]\n",
    "translation = translate_sentence(\n",
    "    input_text=input_test,\n",
    "    model=model,\n",
    "    input_tokenizer=input_tokenizer,\n",
    "    word2idx_outputs=word2idx_outputs,\n",
    "    idx2word_target=idx2word_target,\n",
    "    max_input_len=max_input_len,\n",
    "    max_output_len=max_out_len,   \n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"Input:   \", input_test)\n",
    "print(\"Output:  \", translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se probó con redes más chicas de una capa, dos y tres. \n",
    "- Ampliando el estado oculto, con y sin dropout. \n",
    "- Sin filtrar le token de padding en el crossEntropy, el modelo daba mucho mejor accuracy, pero traducia muy mal. \n",
    "- Filtrando el padding, el accuracy da extremadamente bajo y sigue traduciendo igual de mal."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMniDMuqoKT0lLVAJWxpRSt",
   "collapsed_sections": [],
   "name": "6c - traductor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
