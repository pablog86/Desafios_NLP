{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqO0PRcFsPTe"
   },
   "source": [
    "### Datos\n",
    "El objecto es utilizar datos disponibles del Tatoeba Project de traducciones de texto en diferentes idiomas. Se construirá un modelo traductor de inglés a español seq2seq utilizando encoder-decoder.\\\n",
    "[LINK](https://www.manythings.org/anki/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9276,
     "status": "ok",
     "timestamp": 1749592598575,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "cq3YXak9sGHd"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "#from keras.preprocessing.text import one_hot\n",
    "#from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM, SimpleRNN\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Input\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfa39F4lsLf3"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## LSTM Traductor\n",
    "Ejemplo basado en [LINK](https://stackabuse.com/python-for-nlp-neural-machine-translation-with-seq2seq-in-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1749590111896,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "NkPbHFh7scR8"
   },
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile(\"spa-eng.zip\", 'r') as zip_ref:\n",
    "#     zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 865,
     "status": "ok",
     "timestamp": 1749592599455,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "-9aNLZBDtA5J",
    "outputId": "b7f361ed-b4ec-4f5c-f1b4-a55e66dbe1fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de rows disponibles: 118964\n",
      "Cantidad de rows utilizadas: 23000\n"
     ]
    }
   ],
   "source": [
    "# dataset_file\n",
    "\n",
    "text_file = \"./clase/spa-eng/spa.txt\"\n",
    "with open(text_file, encoding=\"utf8\") as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "# Por limitaciones de RAM no se leen todas las filas\n",
    "MAX_NUM_SENTENCES = 23000\n",
    "\n",
    "# Mezclar el dataset, forzar semilla siempre igual\n",
    "np.random.seed([40])\n",
    "np.random.shuffle(lines)\n",
    "\n",
    "input_sentences = []\n",
    "output_sentences = []\n",
    "output_sentences_inputs = []\n",
    "count = 0\n",
    "\n",
    "for line in lines:\n",
    "    count += 1\n",
    "    if count > MAX_NUM_SENTENCES:\n",
    "        break\n",
    "\n",
    "    # el tabulador señaliza la separación entre las oraciones\n",
    "    # en ambos idiomas\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "\n",
    "    # Input sentence --> eng\n",
    "    # output --> spa\n",
    "    input_sentence, output = line.rstrip().split('\\t')\n",
    "\n",
    "    # output sentence (decoder_output) tiene <eos>\n",
    "    output_sentence = output + ' <eos>'\n",
    "    # output sentence input (decoder_input) tiene <sos>\n",
    "    output_sentence_input = '<sos> ' + output\n",
    "\n",
    "    input_sentences.append(input_sentence)\n",
    "    output_sentences.append(output_sentence)\n",
    "    output_sentences_inputs.append(output_sentence_input)\n",
    "\n",
    "print(\"Cantidad de rows disponibles:\", len(lines))\n",
    "print(\"Cantidad de rows utilizadas:\", len(input_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1749592601236,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "93IGMKFb73q7",
    "outputId": "b643078f-370a-4818-c499-ba86796470bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A deal is a deal.',\n",
       " 'Un trato es un trato. <eos>',\n",
       " '<sos> Un trato es un trato.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentences[0], output_sentences[0], output_sentences_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1749590127792,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "RHNkUaPp6aYq",
    "outputId": "77047449-cdd3-49db-a7b7-dfc46317701e"
   },
   "outputs": [],
   "source": [
    "# # Descargar la carpeta de dataset\n",
    "\n",
    "# import os\n",
    "# if os.access('spa-eng', os.F_OK) is False:\n",
    "#     if os.access('spa-eng.zip', os.F_OK) is False:\n",
    "#         !curl -L -o 'spa-eng.zip' 'http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip'\n",
    "#     !unzip -q spa-eng.zip\n",
    "# else:\n",
    "#     print(\"El dataset ya se encuentra descargado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8P-ynUNP5xp6"
   },
   "source": [
    "### 2 - Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1749592619737,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "5WAZGOTfGyha"
   },
   "outputs": [],
   "source": [
    "# Definir el tamaño máximo del vocabulario\n",
    "MAX_VOCAB_SIZE = 30000\n",
    "# Vamos a necesitar un tokenizador para cada idioma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 158,
     "status": "ok",
     "timestamp": 1749592622203,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "eF1W6peoFGXA",
    "outputId": "1239ce88-bed7-4460-e10c-930e27c45a0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el vocabulario: 7255\n",
      "Sentencia de entrada más larga: 32\n"
     ]
    }
   ],
   "source": [
    "# Tokenizar las palabras con el Tokenizer de Keras\n",
    "# Definir una máxima cantidad de palabras a utilizar:\n",
    "# - num_words --> the maximum number of words to keep, based on word frequency.\n",
    "# - Only the most common num_words-1 words will be kept.\n",
    "#from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# tokenizador de inglés\n",
    "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "input_tokenizer.fit_on_texts(input_sentences)\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
    "\n",
    "word2idx_inputs = input_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n",
    "\n",
    "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
    "print(\"Sentencia de entrada más larga:\", max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1749592624742,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "zBzdKiTVIBYY",
    "outputId": "e65749c3-8f32-4ba6-e17a-6c79b16141ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el vocabulario: 12174\n",
      "Sentencia de salida más larga: 36\n"
     ]
    }
   ],
   "source": [
    "# tokenizador de español\n",
    "# A los filtros de símbolos del Tokenizer agregamos el \"¿\",\n",
    "# sacamos los \"<>\" para que no afectar nuestros tokens\n",
    "output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n')\n",
    "output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)\n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
    "\n",
    "word2idx_outputs = output_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n",
    "\n",
    "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE)\n",
    "# Se suma 1 para incluir el token de palabra desconocida\n",
    "\n",
    "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
    "print(\"Sentencia de salida más larga:\", max_out_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xqb8ZJ4sJHgv"
   },
   "source": [
    "Como era de esperarse, las sentencias en castellano son más largas que en inglés, y lo mismo sucede con su vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1749592626012,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "pgLC706EQx3p"
   },
   "outputs": [],
   "source": [
    "# Por una cuestion de que no explote la RAM se limitará el tamaño de las sentencias de entrada\n",
    "# a la mitad:\n",
    "max_input_len = 32\n",
    "max_output_len = 34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGOn9N57IuYz"
   },
   "source": [
    "A la hora de realiza padding es importante tener en cuenta que en el encoder los ceros se agregan al comienzo y en el decoder al final. Esto es porque la salida del encoder está basado en las últimas palabras de la sentencia (son las más importantes), mientras que en el decoder está basado en el comienzo de la secuencia de salida ya que es la realimentación del sistema y termina con fin de sentencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1749592627650,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "q0Ob4hAWJkcv",
    "outputId": "d5a61c1a-edc5-48f9-9c9b-60240ac159e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de rows del dataset: 23000\n",
      "encoder_input_sequences shape: (23000, 32)\n",
      "decoder_input_sequences shape: (23000, 34)\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de rows del dataset:\", len(input_integer_seq))\n",
    "\n",
    "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n",
    "\n",
    "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
    "print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wK4blEEsRQv3"
   },
   "source": [
    "La última capa del modelo (softmax) necesita que los valores de salida\n",
    "del decoder (decoder_sequences) estén en formato oneHotEncoder.\\\n",
    "Se utiliza \"decoder_output_sequences\" con la misma estrategia con que se transformó la entrada del decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1749592629471,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "3toZyIVEOC18",
    "outputId": "8afe6b39-e38f-4957-a557-d3ee8f158753"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23000, 34, 12175)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
    "decoder_targets = to_categorical(decoder_output_sequences, num_classes=num_words_output)\n",
    "decoder_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CJIsLBbj6rg"
   },
   "source": [
    "### 3 - Preparar los embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1749591826696,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "Jlnzm7oOuC4z",
    "outputId": "fa6b741f-c8c9-488e-abf7-c5f81d192d94"
   },
   "outputs": [],
   "source": [
    "# Descargar los embeddings desde un google drive (es la forma más rápida)\n",
    "# NOTA: No hay garantía de que estos links perduren, en caso de que no estén\n",
    "# disponibles descargar de la página oficial como se explica en el siguiente bloque de código\n",
    "# import os\n",
    "# import gdown\n",
    "# if os.access('gloveembedding.pkl', os.F_OK) is False:\n",
    "#     url = 'https://drive.google.com/uc?id=1KY6avD5I1eI2dxQzMkR3WExwKwRq2g94&export=download'\n",
    "#     output = 'gloveembedding.pkl'\n",
    "#     gdown.download(url, output, quiet=False)\n",
    "# else:\n",
    "#     print(\"Los embeddings gloveembedding.pkl ya están descargados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1412,
     "status": "ok",
     "timestamp": 1749591830568,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "oGdGSYZ_pSNQ",
    "outputId": "fe453b67-859e-41c7-d026-d6238a5c3071"
   },
   "outputs": [],
   "source": [
    "# En caso de que gdown de algún error de permisos intentar descargar los\n",
    "# embeddings con curl:\n",
    "\n",
    "# !curl -L -o 'gloveembedding.pkl' 'https://drive.google.com/u/0/uc?id=1KY6avD5I1eI2dxQzMkR3WExwKwRq2g94&export=download&confirm=t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1749592647592,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "ZgqtV8GpkSc8"
   },
   "outputs": [],
   "source": [
    "# import logging\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "# from io import StringIO\n",
    "# import pickle\n",
    "\n",
    "# class WordsEmbeddings(object):\n",
    "#     logger = logging.getLogger(__name__)\n",
    "\n",
    "#     def __init__(self):\n",
    "#         # load the embeddings\n",
    "#         words_embedding_pkl = Path(self.PKL_PATH)\n",
    "#         if not words_embedding_pkl.is_file():\n",
    "#             words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
    "#             assert words_embedding_txt.is_file(), 'Words embedding not available'\n",
    "#             embeddings = self.convert_model_to_pickle()\n",
    "#         else:\n",
    "#             embeddings = self.load_model_from_pickle()\n",
    "#         self.embeddings = embeddings\n",
    "#         # build the vocabulary hashmap\n",
    "#         index = np.arange(self.embeddings.shape[0])\n",
    "#         # Dicctionarios para traducir de embedding a IDX de la palabra\n",
    "#         self.word2idx = dict(zip(self.embeddings['word'], index))\n",
    "#         self.idx2word = dict(zip(index, self.embeddings['word']))\n",
    "\n",
    "#     def get_words_embeddings(self, words):\n",
    "#         words_idxs = self.words2idxs(words)\n",
    "#         return self.embeddings[words_idxs]['embedding']\n",
    "\n",
    "#     def words2idxs(self, words):\n",
    "#         return np.array([self.word2idx.get(word, -1) for word in words])\n",
    "\n",
    "#     def idxs2words(self, idxs):\n",
    "#         return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
    "\n",
    "#     def load_model_from_pickle(self):\n",
    "#         self.logger.debug(\n",
    "#             'loading words embeddings from pickle {}'.format(\n",
    "#                 self.PKL_PATH\n",
    "#             )\n",
    "#         )\n",
    "#         max_bytes = 2**28 - 1 # 256MB\n",
    "#         bytes_in = bytearray(0)\n",
    "#         input_size = os.path.getsize(self.PKL_PATH)\n",
    "#         with open(self.PKL_PATH, 'rb') as f_in:\n",
    "#             for _ in range(0, input_size, max_bytes):\n",
    "#                 bytes_in += f_in.read(max_bytes)\n",
    "#         embeddings = pickle.loads(bytes_in)\n",
    "#         self.logger.debug('words embeddings loaded')\n",
    "#         return embeddings\n",
    "\n",
    "#     def convert_model_to_pickle(self):\n",
    "#         # create a numpy strctured array:\n",
    "#         # word     embedding\n",
    "#         # U50      np.float32[]\n",
    "#         # word_1   a, b, c\n",
    "#         # word_2   d, e, f\n",
    "#         # ...\n",
    "#         # word_n   g, h, i\n",
    "#         self.logger.debug(\n",
    "#             'converting and loading words embeddings from text file {}'.format(\n",
    "#                 self.WORD_TO_VEC_MODEL_TXT_PATH\n",
    "#             )\n",
    "#         )\n",
    "#         structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
    "#                      ('embedding', np.float32, (self.N_FEATURES,))]\n",
    "#         structure = np.dtype(structure)\n",
    "#         # load numpy array from disk using a generator\n",
    "#         with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
    "#             embeddings_gen = (\n",
    "#                 (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n",
    "#                 if len(line.split()[1:]) == self.N_FEATURES\n",
    "#             )\n",
    "#             embeddings = np.fromiter(embeddings_gen, structure)\n",
    "#         # add a null embedding\n",
    "#         null_embedding = np.array(\n",
    "#             [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
    "#             dtype=structure\n",
    "#         )\n",
    "#         embeddings = np.concatenate([embeddings, null_embedding])\n",
    "#         # dump numpy array to disk using pickle\n",
    "#         max_bytes = 2**28 - 1 # # 256MB\n",
    "#         bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#         with open(self.PKL_PATH, 'wb') as f_out:\n",
    "#             for idx in range(0, len(bytes_out), max_bytes):\n",
    "#                 f_out.write(bytes_out[idx:idx+max_bytes])\n",
    "#         self.logger.debug('words embeddings loaded')\n",
    "#         return embeddings\n",
    "\n",
    "\n",
    "# class GloveEmbeddings(WordsEmbeddings):\n",
    "#     WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n",
    "#     PKL_PATH = 'gloveembedding.pkl'\n",
    "#     N_FEATURES = 50\n",
    "#     WORD_MAX_SIZE = 60\n",
    "\n",
    "# class FasttextEmbeddings(WordsEmbeddings):\n",
    "#     WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
    "#     PKL_PATH = 'fasttext.pkl'\n",
    "#     N_FEATURES = 300\n",
    "#     WORD_MAX_SIZE = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 4540,
     "status": "ok",
     "timestamp": 1749592655435,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "Mosj2-x-kXBK"
   },
   "outputs": [],
   "source": [
    "# Por una cuestion de RAM se utilizarán los embeddings de Glove de dimension 50\n",
    "# model_embeddings = GloveEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1749592655503,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "b9FS8ca1ke_B",
    "outputId": "b3cd3a7e-e7cb-4cef-8815-02de444e6c71"
   },
   "outputs": [],
   "source": [
    "# Crear la Embedding matrix de las secuencias\n",
    "# en inglés\n",
    "\n",
    "# print('preparing embedding matrix...')\n",
    "# embed_dim = model_embeddings.N_FEATURES\n",
    "# words_not_found = []\n",
    "\n",
    "# # word_index provieen del tokenizer\n",
    "\n",
    "# nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs))+ 1 # vocab_size\n",
    "# embedding_matrix = np.zeros((nb_words, embed_dim))\n",
    "# for word, i in word2idx_inputs.items():\n",
    "#     if i >= nb_words:\n",
    "#         continue\n",
    "#     embedding_vector = model_embeddings.get_words_embeddings(word)[0]\n",
    "#     if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
    "\n",
    "#         embedding_matrix[i] = embedding_vector\n",
    "#     else:\n",
    "#         # words not found in embedding index will be all-zeros.\n",
    "#         words_not_found.append(word)\n",
    "\n",
    "# print('number of null word embeddings:', np.sum(np.sum(embedding_matrix**2, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1749592657456,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "FpzJODHBlAtE",
    "outputId": "bf905a0e-cf4c-41eb-f744-f29a08f83308"
   },
   "outputs": [],
   "source": [
    "# # Dimensión de los embeddings de la secuencia en inglés\n",
    "# embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7256, 300)\n",
      "(12175, 300)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "model_embeddings = load_facebook_vectors(\"clase/cc.en.300.bin\")  \n",
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "model_embeddings_es = load_facebook_vectors(\"clase/cc.es.300.bin\")\n",
    "vocab_size_in  = max(word2idx_inputs .values()) + 1   \n",
    "vocab_size_out = max(word2idx_outputs.values()) + 1   \n",
    "embed_dim = 300\n",
    "# Inglés\n",
    "embedding_matrix = np.zeros((vocab_size_in, embed_dim), dtype=np.float32)\n",
    "for w, idx in word2idx_inputs.items():\n",
    "    # idx incluye todos los valores hasta max_index\n",
    "    if w in model_embeddings:\n",
    "        embedding_matrix[idx] = model_embeddings[w]\n",
    "# Español\n",
    "embedding_matrix_es = np.zeros((vocab_size_out, embed_dim), dtype=np.float32)\n",
    "for w, idx in word2idx_outputs.items():\n",
    "    if w in model_embeddings_es:\n",
    "        embedding_matrix_es[idx] = model_embeddings_es[w]\n",
    "print(embedding_matrix.shape)\n",
    "print(embedding_matrix_es.shape)\n",
    "nb_words = embedding_matrix.shape[0]                # Vocablos en Inglés\n",
    "num_words_output = embedding_matrix_es.shape[0]     # Vocablos en Español"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vKbhjtIwPgM"
   },
   "source": [
    "### 4 - Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "n_units = 256\n",
    "\n",
    "# Encoder Inglés\n",
    "encoder_inputs  = Input(shape=(max_input_len,), name='encoder_input')\n",
    "encoder_embedding = Embedding(\n",
    "        input_dim=nb_words,              # tamaño vocab inglés\n",
    "        output_dim=embed_dim,\n",
    "        weights=[embedding_matrix],      # FastText inglés\n",
    "        input_length=max_input_len,\n",
    "        trainable=False,                 # congelado\n",
    "        mask_zero=True)                  # ignora <pad>=0 en LSTM\n",
    "\n",
    "encoder_embedded = encoder_embedding(encoder_inputs)\n",
    "encoder_lstm   = LSTM(n_units, return_state=True, name='encoder_lstm')\n",
    "_, state_h, state_c = encoder_lstm(encoder_embedded)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder Español\n",
    "decoder_inputs = Input(shape=(max_output_len,), name='decoder_input')\n",
    "decoder_embedding = Embedding(\n",
    "        input_dim=num_words_output,      # tamaño vocab español\n",
    "        output_dim=embed_dim,\n",
    "        weights=[embedding_matrix_es],   # FastText español\n",
    "        input_length=max_output_len,\n",
    "        trainable=False,\n",
    "        mask_zero=True)\n",
    "\n",
    "decoder_embedded = decoder_embedding(decoder_inputs)\n",
    "decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedded, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_words_output, activation='softmax', name='decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Seq2Seq\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Usa índices de palabras como y_true  ➜ pérdida sparse\n",
    "model.compile( optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])   # loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='auto')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "executionInfo": {
     "elapsed": 2728,
     "status": "ok",
     "timestamp": 1749592664635,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "t_urD1qO2kOx",
    "outputId": "93ffd1d8-3bd8-4614-a252-59478a1f60cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pablo\\IA-repos\\Desafios_NLP\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,176,800</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,116,800</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">570,368</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12175</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,128,975</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m2,176,800\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m3,116,800\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │    \u001b[38;5;34m570,368\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m525,312\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m12175\u001b[0m) │  \u001b[38;5;34m3,128,975\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,518,255</span> (36.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,518,255\u001b[0m (36.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,341,455</span> (28.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,341,455\u001b[0m (28.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,176,800</span> (8.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,176,800\u001b[0m (8.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from keras.models import Model\n",
    "# from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "# n_units = 256\n",
    "\n",
    "# # define training encoder\n",
    "# # encoder_inputs = Input(shape=(max_input_len))\n",
    "# encoder_inputs = Input(shape=(max_input_len,), name='encoder_input')\n",
    "\n",
    "# #encoder_embedding_layer = Embedding(num_words, EMBEDDING_SIZE, weights=[embedding_matrix], input_length=max_input_len)\n",
    "\n",
    "# encoder_embedding_layer = Embedding(\n",
    "#           input_dim=nb_words,  # definido en el Tokenizador\n",
    "#           output_dim=embed_dim,  # dimensión de los embeddings utilizados\n",
    "#           input_length=max_input_len, # tamaño máximo de la secuencia de entrada\n",
    "#           weights=[embedding_matrix],  # matrix de embeddings\n",
    "#           trainable=False)      # marcar como layer no entrenable\n",
    "\n",
    "# encoder_inputs_x = encoder_embedding_layer(encoder_inputs)\n",
    "\n",
    "# encoder = LSTM(n_units, return_state=True)\n",
    "# encoder_outputs, state_h, state_c = encoder(encoder_inputs_x)\n",
    "# encoder_states = [state_h, state_c]\n",
    "\n",
    "# # define training decoder\n",
    "# #decoder_inputs = Input(shape=(max_out_len))\n",
    "# decoder_inputs = Input(shape=(max_input_len,), name='decoder_input')\n",
    "# decoder_embedding_layer = Embedding(input_dim=num_words_output, output_dim=n_units, input_length=max_out_len)\n",
    "# decoder_inputs_x = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "# decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\n",
    "# decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n",
    "\n",
    "# # Dense\n",
    "# decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)\n",
    "# model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1749592667396,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "Hp7CotExyuNr",
    "outputId": "a185036f-4556-43b1-8b1a-cb83f156bbcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_sequences.shape: (23000, 32)\n",
      "decoder_input_sequences.shape: (23000, 34)\n",
      "decoder_targets.shape: (23000, 34, 12175)\n"
     ]
    }
   ],
   "source": [
    "print(\"encoder_input_sequences.shape:\", encoder_input_sequences.shape)      # Debe ser (N, 16)\n",
    "print(\"decoder_input_sequences.shape:\", decoder_input_sequences.shape)      # Debe ser (N, 16)\n",
    "print(\"decoder_targets.shape:\", decoder_targets.shape)                      # Debe ser (N, 16, num_words_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 611,
     "status": "ok",
     "timestamp": 1749592670783,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "2ljAyiBbG10U",
    "outputId": "5a02defe-8325-4ad8-f2af-d05c312427dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "# Modelo completo (encoder+decoder) para poder entrenar\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 939
    },
    "executionInfo": {
     "elapsed": 125,
     "status": "ok",
     "timestamp": 1749592673437,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "s1Wc1pnhIKJ6",
    "outputId": "7ad06de6-9fa2-4f79-8e43-15e231a8f96d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "# Modelo solo encoder\n",
    "\n",
    "# define inference encoder\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "plot_model(encoder_model, to_file='encoder_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 377,
     "status": "ok",
     "timestamp": 1749592676546,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "L_xanat4INez",
    "outputId": "5d5fb8a6-e56b-4337-9ecd-a73804eea0f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "# Modelo solo decoder (para realizar inferencia)\n",
    "\n",
    "# define inference decoder\n",
    "decoder_state_input_h = Input(shape=(n_units,))\n",
    "decoder_state_input_c = Input(shape=(n_units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# En cada predicción habrá una sola palabra de entrada al decoder,\n",
    "# que es la realimentación de la palabra anterior\n",
    "# por lo que hay que modificar el input shape de la layer de Embedding\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding_layer(decoder_inputs_single)\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs_single] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "plot_model(decoder_model, to_file='decoder_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',       # métrica que se vigila\n",
    "    patience=5,               # nº de epochs sin mejora antes de frenar\n",
    "    min_delta=1e-4,           # mejora mínima que se considera significativa\n",
    "    mode='min',               # 'min' porque queremos que val_loss baje\n",
    "    restore_best_weights=True # al parar, deja los pesos del mejor epoch\n",
    ")\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'best_model.h5', monitor='val_loss',\n",
    "    save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 89630,
     "status": "ok",
     "timestamp": 1749592769966,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "VnlIx1Vezjwc",
    "outputId": "d46e1bc9-75a9-49bd-90cc-49103231555f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 1 of layer \"functional\" is incompatible with the layer: expected shape=(None, 32), found shape=(32, 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m hist = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mencoder_input_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_sequences\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Pablo\\IA-repos\\Desafios_NLP\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Pablo\\IA-repos\\Desafios_NLP\\venv\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:245\u001b[39m, in \u001b[36massert_input_compatibility\u001b[39m\u001b[34m(input_spec, inputs, layer_name)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim != dim:\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    246\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of layer \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m is \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    247\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mincompatible with the layer: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    249\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    250\u001b[39m         )\n",
      "\u001b[31mValueError\u001b[39m: Input 1 of layer \"functional\" is incompatible with the layer: expected shape=(None, 32), found shape=(32, 34)"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    [encoder_input_sequences, decoder_input_sequences],\n",
    "    decoder_targets,\n",
    "    epochs=15,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop, checkpoint]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1749592884196,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "OVz1uug_zu2J",
    "outputId": "e949b6a6-38be-4d7a-8c36-e195275c4ad7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Entrenamiento\n",
    "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['val_accuracy'], label='valid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zbwn0ekDy_s2"
   },
   "source": [
    "### 5 - Inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1749592887935,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "jnkl3mSpsU_7",
    "outputId": "09e146a5-a911-4424-e8b1-2b714813cd5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nStep 1:\\nA deal is a deal -> Encoder -> enc(h1,c1)\\n\\nenc(h1,c1) + <sos> -> Decoder -> Un + dec(h1,c1)\\n\\nstep 2:\\ndec(h1,c1) + Un -> Decoder -> trato + dec(h2,c2)\\n\\nstep 3:\\ndec(h2,c2) + trato -> Decoder -> es + dec(h3,c3)\\n\\nstep 4:\\ndec(h3,c3) + es -> Decoder -> un + dec(h4,c4)\\n\\nstep 5:\\ndec(h4,c4) + un -> Decoder -> trato + dec(h5,c5)\\n\\nstep 6:\\ndec(h5,c5) + trato. -> Decoder -> <eos> + dec(h6,c6)\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Step 1:\n",
    "A deal is a deal -> Encoder -> enc(h1,c1)\n",
    "\n",
    "enc(h1,c1) + <sos> -> Decoder -> Un + dec(h1,c1)\n",
    "\n",
    "step 2:\n",
    "dec(h1,c1) + Un -> Decoder -> trato + dec(h2,c2)\n",
    "\n",
    "step 3:\n",
    "dec(h2,c2) + trato -> Decoder -> es + dec(h3,c3)\n",
    "\n",
    "step 4:\n",
    "dec(h3,c3) + es -> Decoder -> un + dec(h4,c4)\n",
    "\n",
    "step 5:\n",
    "dec(h4,c4) + un -> Decoder -> trato + dec(h5,c5)\n",
    "\n",
    "step 6:\n",
    "dec(h5,c5) + trato. -> Decoder -> <eos> + dec(h6,c6)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1749592890866,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "71XeCtfYmOFx"
   },
   "outputs": [],
   "source": [
    "# Armar los conversores de índice a palabra:\n",
    "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1749592895079,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "MlUyp9M6ua2V"
   },
   "outputs": [],
   "source": [
    "def translate_sentence(input_seq):\n",
    "    # Se transforma la sequencia de entrada a los estados \"h\" y \"c\" de la LSTM\n",
    "    # para enviar la primera vez al decoder\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Se inicializa la secuencia de entrada al decoder como \"<sos>\"\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "\n",
    "    # Se obtiene el índice que finaliza la inferencia\n",
    "    eos = word2idx_outputs['<eos>']\n",
    "\n",
    "    output_sentence = []\n",
    "    for _ in range(max_out_len):\n",
    "        # Predicción del próximo elemento\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        idx = np.argmax(output_tokens[0, 0, :])\n",
    "\n",
    "        # Si es \"end of sentece <eos>\" se acaba\n",
    "        if eos == idx:\n",
    "            break\n",
    "\n",
    "        # Transformar idx a palabra\n",
    "        word = ''\n",
    "        if idx > 0:\n",
    "            word = idx2word_target[idx]\n",
    "            output_sentence.append(word)\n",
    "\n",
    "        # Actualizar los estados dada la última predicción\n",
    "        states_value = [h, c]\n",
    "\n",
    "        # Actualizar secuencia de entrada con la salida (re-alimentación)\n",
    "        target_seq[0, 0] = idx\n",
    "\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1118,
     "status": "ok",
     "timestamp": 1749592898849,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "ZhGVjLKcunxW",
    "outputId": "727e7410-fd25-4e09-b6ed-b596026dd1eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "-\n",
      "Input: Tom is naked.\n",
      "Response: tom está en peligro\n"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(len(input_sentences))\n",
    "input_seq = encoder_input_sequences[i:i+1]\n",
    "translation = translate_sentence(input_seq)\n",
    "print('-')\n",
    "print('Input:', input_sentences[i])\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 552,
     "status": "ok",
     "timestamp": 1749592904808,
     "user": {
      "displayName": "Pablo Gomez",
      "userId": "12157267146123218304"
     },
     "user_tz": 180
    },
    "id": "KYZ1Q_Z_2G4m",
    "outputId": "fd4f0988-3786-4895-8dd8-344535d7a9c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: My mother say hi.\n",
      "Representacion en vector de tokens de ids [15, 203, 132, 3030]\n",
      "Padding del vector: [[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    15  203  132 3030]]\n",
      "Input: My mother say hi.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Response: mi padre me ha ido\n"
     ]
    }
   ],
   "source": [
    "input_test = \"My mother say hi.\"\n",
    "print('Input:', input_test)\n",
    "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
    "print(\"Representacion en vector de tokens de ids\", integer_seq_test)\n",
    "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
    "print(\"Padding del vector:\", encoder_sequence_test)\n",
    "\n",
    "print('Input:', input_test)\n",
    "translation = translate_sentence(encoder_sequence_test)\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkOjSJweqdF8"
   },
   "source": [
    "### 6 - Conclusión\n",
    "A primera vista parece que el modelo tendría que funcionar muy bien por el accuracy alcanzado. La realidad es que las respuestas no tienen que ver demasiado con la pregunta/traducción pero la respuesta en si tiene bastante coherencia.\\\n",
    "Para poder mejorar el modelo haría falta poder consumir todo el dataset y todo el vocabulario, pero la cantidad de RAM no es suficiente.\\\n",
    "Este problema se resuelve con:\n",
    "- Utilizando un DataGenerator para no levantar todo el dataset junto en el entrenamiento.\n",
    "- Transfer learning evitando tener que entrenar todo el modelo  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSy0kaSKuC4-"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
